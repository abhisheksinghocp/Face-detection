{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "import numpy as np\n",
    "import cv2,math\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import YouTubeVideo\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "print (cv2.__version__)\n",
    "\n",
    "def plt_show(image, title=\"\"):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.imshow(image, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "    \n",
    "class FaceDetector(object):\n",
    "    def __init__(self, xml_path):\n",
    "        self.classifier = cv2.CascadeClassifier(xml_path)\n",
    "    \n",
    "    def detect(self, image, biggest_only=True):\n",
    "        scale_factor = 1.2\n",
    "        min_neighbors = 5\n",
    "        min_size = (30, 30)\n",
    "        biggest_only = True\n",
    "        flags = cv2.CASCADE_FIND_BIGGEST_OBJECT | \\\n",
    "                    cv2.CASCADE_DO_ROUGH_SEARCH if biggest_only else \\\n",
    "                    cv2.CASCADE_SCALE_IMAGE\n",
    "        faces_coord = self.classifier.detectMultiScale(image,\n",
    "                                                       scaleFactor=scale_factor,\n",
    "                                                       minNeighbors=min_neighbors,\n",
    "                                                       minSize=min_size,\n",
    "                                                       flags=flags)\n",
    "        return faces_coord\n",
    "    \n",
    "class VideoCamera(object):\n",
    "    def __init__(self, index=0):\n",
    "        self.video = cv2.VideoCapture(index)\n",
    "        self.index = index\n",
    "        print (self.video.isOpened())\n",
    "\n",
    "    def __del__(self):\n",
    "        self.video.release()\n",
    "    \n",
    "    def get_frame(self, in_grayscale=False):\n",
    "        _, frame = self.video.read()\n",
    "        if in_grayscale:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        return frame\n",
    "\n",
    "def cut_faces(image, faces_coord):\n",
    "    faces = []\n",
    "    \n",
    "    for (x, y, w, h) in faces_coord:\n",
    "        w_rm = int(0.3 * w / 2)\n",
    "        faces.append(image[y: y + h, x + w_rm: x + w - w_rm])\n",
    "         \n",
    "    return faces\n",
    "\n",
    "def normalize_intensity(images):\n",
    "    images_norm = []\n",
    "    for image in images:\n",
    "        is_color = len(image.shape) == 3 \n",
    "        if is_color:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        images_norm.append(cv2.equalizeHist(image))\n",
    "    return images_norm\n",
    "\n",
    "def resize(images, size=(50, 50)):\n",
    "    images_norm = []\n",
    "    for image in images:\n",
    "        if image.shape < size:\n",
    "            image_norm = cv2.resize(image, size, \n",
    "                                    interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            image_norm = cv2.resize(image, size, \n",
    "                                    interpolation=cv2.INTER_CUBIC)\n",
    "        images_norm.append(image_norm)\n",
    "\n",
    "    return images_norm\n",
    "\n",
    "def normalize_faces(frame, faces_coord):\n",
    "    faces = cut_faces(frame, faces_coord)\n",
    "    faces = normalize_intensity(faces)\n",
    "    faces = resize(faces)\n",
    "    return faces\n",
    "\n",
    "def draw_rectangle(image, coords):\n",
    "    for (x, y, w, h) in coords:\n",
    "        w_rm = int(0.2 * w / 2) \n",
    "        cv2.rectangle(image, (x + w_rm, y), (x + w - w_rm, y + h), \n",
    "                              (150, 150, 0), 8)\n",
    "\n",
    "def collect_dataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "    labels_dic = {}\n",
    "    people = [person for person in os.listdir(\"A:\\people\\/\")]\n",
    "    for i, person in enumerate(people):\n",
    "        labels_dic[i] = person\n",
    "        for image in os.listdir(\"A:\\people\\/\" + person):\n",
    "            images.append(cv2.imread(\"A:\\people\\/\" + person + '/' + image, 0))\n",
    "            labels.append(i)\n",
    "    return (images, np.array(labels), labels_dic)\n",
    "\n",
    "\n",
    "#webcam = VideoCamera()\n",
    "detector = FaceDetector('C:\\/Users\\/abhishek\\Desktop\\haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Trained Succesfully\n"
     ]
    }
   ],
   "source": [
    "images, labels, labels_dic = collect_dataset()\n",
    "\n",
    "rec_eig = cv2.face.createEigenFaceRecognizer()\n",
    "rec_eig.train(images, labels)\n",
    "\n",
    "# needs at least two people \n",
    "rec_fisher = cv2.face.createFisherFaceRecognizer()\n",
    "rec_fisher.train(images, labels)\n",
    "\n",
    "rec_lbph = cv2.face.createLBPHFaceRecognizer()\n",
    "rec_lbph.train(images, labels)\n",
    "\n",
    "print (\"Models Trained Succesfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "detector = FaceDetector('C:\\/Users\\/abhishek\\Desktop\\haarcascade_frontalface_default.xml')\n",
    "webcam = VideoCamera(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_label(image, text, coord, conf, threshold):\n",
    "    if conf < threshold: # apply threshold \n",
    "        cv2.putText(image, text.capitalize(),\n",
    "                    coord,\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)\n",
    "    else:\n",
    "        cv2.putText(image, \"Unknown\",\n",
    "                    coord,\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-02902e94ccb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdraw_rectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfaces_coord\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# rectangle around face\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     cv2.putText(frame, \"ESC to exit\", (5, frame.shape[0] - 5),\n\u001b[0m\u001b[1;32m     20\u001b[0m                     cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2, cv2.LINE_AA)\n\u001b[1;32m     21\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PyData Tutorial\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# live feed in external\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def live_recognition(index, webcam):\n",
    "    global double_frame\n",
    "    detector = FaceDetector('C:\\/Users\\/abhishek\\Desktop\\haarcascade_frontalface_default.xml')\n",
    "    while True:\n",
    "        frame = webcam.get_frame()\n",
    "        faces_coord = detector.detect(frame, False) # detect more than one face\n",
    "        if len(faces_coord):\n",
    "            faces = normalize_faces(frame, faces_coord) # norm pipeline\n",
    "            for i, face in enumerate(faces): # for each detected face\n",
    "                collector = cv2.face.MinDistancePredictCollector()\n",
    "                rec_lbph.predict(face, collector)\n",
    "                conf = collector.getDist()\n",
    "                pred = collector.getLabel()\n",
    "                threshold = 140\n",
    "                draw_label(frame, labels_dic[pred], \n",
    "                           (faces_coord[i][0], faces_coord[i][1] - 10), \n",
    "                           conf, threshold)\n",
    "            draw_rectangle(frame, faces_coord) # rectangle around face\n",
    "        cv2.putText(frame, \"ESC to exit\", (5, frame.shape[0] - 5),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2, \n",
    "                    cv2.LINE_AA)\n",
    "        if index == 0:\n",
    "            cv2.putText(frame, \"Laptop\", (frame.shape[1] - 100, 30),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(frame, \"External\", (frame.shape[1] - 120, 30),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2, cv2.LINE_AA)\n",
    "        double_frame[0 : 481, index * 640 : (index +1 ) * 640] = frame # copy new frame to FS\n",
    "        cv2.imshow(\"PyData Tutorial\", double_frame) # live feed in external\n",
    "        if cv2.waitKey(30) & 0xFF == 27:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4e101ca1dd9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfaces_coord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_faces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfaces_coord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mwebcam\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# get sample test\n",
    "webcam = VideoCamera(0)\n",
    "frame = webcam.get_frame()\n",
    "detector = FaceDetector('C:\\/Users\\/abhishek\\Desktop\\haarcascade_frontalface_default.xml')\n",
    "frame = webcam.get_frame()\n",
    "faces_coord = detector.detect(frame)\n",
    "faces = normalize_faces(frame,faces_coord)\n",
    "face = faces[0]\n",
    "plt_show(face)\n",
    "del webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "cv2.namedWindow(\"PyData Tutorial\", cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty(\"PyData Tutorial\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "#cv2.namedWindow(\"PyData Tutorial 1\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "webcam_0 = VideoCamera(0)\n",
    "#webcam_1 = VideoCamera(1)\n",
    "\n",
    "single_frame = np.zeros_like(webcam_0.get_frame())\n",
    "double_frame = np.hstack((single_frame, single_frame))\n",
    "\n",
    "thread_0 = Thread(target = live_recognition, args = (0, webcam_0))\n",
    "#thread_1 = Thread(target = live_recognition, args = (1, webcam_1))\n",
    "thread_0.start()\n",
    "#thread_1.start()\n",
    "#thread_1.join()\n",
    "thread_0.join()\n",
    "del webcam_0\n",
    "#del webcam_1\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
